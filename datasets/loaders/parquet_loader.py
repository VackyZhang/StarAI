"""
parquet_loader.py

ä» Parquet æ–‡ä»¶ä¸­åŠ è½½æ•°æ®ï¼Œæ”¯æŒé€šè¿‡é…ç½®æ–‡ä»¶è·¯å¾„åŠ è½½ã€‚
"""

import os
import pandas as pd
from datasets.configs.dataset_config import DATASET_CONFIG
from common.logger import get_logger

logger = get_logger("ParquetLoader")


def load_dataset(name: str, split: str = "train", index_col: str = "date") -> pd.DataFrame:
    """
    ä» Parquet æ–‡ä»¶åŠ è½½æ•°æ®ï¼Œå¹¶è¿”å› DataFrameã€‚

    å‚æ•°:
        name (str): æ•°æ®é›†åç§°ï¼Œå¦‚ "000001.SZ"
        split (str): æ•°æ®é›†åˆ‡åˆ†ï¼Œå¦‚ "train", "test"
        index_col (str): è®¾ç½® DataFrame çš„ç´¢å¼•åˆ—ï¼Œé»˜è®¤ä¸º "date"

    è¿”å›:
        pd.DataFrame: è¿”å›åŠ è½½çš„æ•°æ®é›†
    """
    data_dir = DATASET_CONFIG["processed_dir"]
    file_path = os.path.join(data_dir, name, f"{split}.parquet")

    if not os.path.exists(file_path):
        logger.error(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {file_path}")
        raise FileNotFoundError(f"æ— æ³•åŠ è½½æ•°æ®é›†ï¼š{file_path}")

    try:
        df = pd.read_parquet(file_path)
        df.set_index(index_col, inplace=True)
        logger.info(f"âœ… åŠ è½½ Parquet æ•°æ®é›†: {file_path}")
        return df
    except Exception as e:
        logger.exception(f"ğŸ“› åŠ è½½ Parquet å¤±è´¥: {file_path}")
        raise e
