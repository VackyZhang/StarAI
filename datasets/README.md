âœ… æ‹†åˆ†çš„ç†ç”±ï¼ˆé€‚åˆä¸­å¤§å‹é¡¹ç›®ï¼‰ï¼š
èŒè´£æ›´æ¸…æ™°ï¼š
data/ æ˜¯â€œè·å–å’Œç”Ÿæˆæ•°æ®â€ï¼Œ
datasets/ æ˜¯â€œè®©æ¨¡å‹æ¶ˆè´¹æ•°æ®â€ã€‚

é€‚åˆå›¢é˜Ÿåˆ†å·¥ï¼š
æ•°æ®å·¥ç¨‹å¸ˆç»´æŠ¤ data/ï¼Œç®—æ³•å·¥ç¨‹å¸ˆä½¿ç”¨ datasets/ã€‚
æ”¯æŒå¤šä¸ªæ•°æ®æ¥æºç»Ÿä¸€æ¥å£ï¼ˆå¦‚ CSV / Parquet / SQL / APIï¼‰
æ–¹ä¾¿åæœŸå¯¹æ¥ PyTorch Dataset / Tensorflow Dataset


# ğŸ“¦ datasets

ç”¨äºæ¨¡å‹è®­ç»ƒå‰çš„æ•°æ®åŠ è½½é€»è¾‘å°è£…ï¼ŒåŒ…æ‹¬ CSV -> DataFrame -> æ¨¡å‹è¾“å…¥ç­‰è½¬æ¢è¿‡ç¨‹ã€‚

### ğŸ“ å­ç›®å½•è¯´æ˜

- `loaders/`ï¼šåŠ è½½å¤„ç†å¥½çš„æ•°æ®ï¼ˆå¦‚ data/processedï¼‰ä¸º DataFrame
- `configs/`ï¼šå®šä¹‰å’ŒåŠ è½½æ•°æ®è·¯å¾„ã€ç»“æ„ç­‰é…ç½®


datasets/
â”œâ”€â”€ __init__.py                            # å¯ç©ºï¼Œç”¨äºæ ‡è®°åŒ…ç»“æ„
â”œâ”€â”€ builder.py                             # ä¸»å…¥å£ï¼šç»„ç»‡åŠ è½½ã€ç‰¹å¾æ„é€ ã€æ‹†åˆ†ç­‰æµç¨‹
â”œâ”€â”€ splitter.py                            # æ‹†åˆ†æ•°æ®ä¸º train/val/test çš„å·¥å…·
â”œâ”€â”€ features.py                            # ç‰¹å¾æ„é€ ï¼Œå¦‚æ·»åŠ æŠ€æœ¯æŒ‡æ ‡ã€æ»‘çª—ç­‰
â”‚
â”œâ”€â”€ loaders/                               # æ•°æ®åŠ è½½å­æ¨¡å—ï¼šæ”¯æŒ CSVã€Parquetã€SQL
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ csv_loader.py                      # âœ… å®ç°ï¼šä» data/processed åŠ è½½ CSV
â”‚   â”œâ”€â”€ parquet_loader.py                  # ğŸ”² é¢„ç•™ï¼šä» Parquet åŠ è½½æ•°æ®
â”‚   â””â”€â”€ sql_loader.py                      # ğŸ”² é¢„ç•™ï¼šä»æ•°æ®åº“ï¼ˆå¦‚ ClickHouseï¼‰åŠ è½½
â”‚
â”œâ”€â”€ configs/                               # æ•°æ®é›†ç›¸å…³é…ç½®ï¼ˆä¸ä¾èµ–ä¸» config/ï¼‰
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ dataset_config.py                  # âœ… å®ç°ï¼šåŠ è½½ dataset_config.yaml
â”‚   â””â”€â”€ dataset_config.yaml                # âœ… ç¤ºä¾‹ï¼šæŒ‡å®š processed_dirã€raw_dir ç­‰
